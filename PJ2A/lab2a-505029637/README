-------------
Documentation
-------------

NAME: Haoran Wang
ID: 505029637
EMAIL: hwan252@ucla.edu

---------
Porject2A
---------
Source files: lab2_add.c lab2_list.c SortedList.h SortedList.c 
Graphs: lab2_add-1.png lab2_add-2.png lab2_add-3.png lab2_add-4.png lab2_add-5.png lab2_list-1.png lab2_list-2.png lab2_list-3.png lab2_list-4.png
Scripts: lab2_add.gp lab2_list.gp
Data files: lab2_add.csv lab2_list.csv
README
Makefile

Q2.1.1:
	The race condition indicates it is possible that a portion of data might be falsely operated. However, it is not always the case. There is a certain possibility that it will happen but it is not deterministic. The larger the iteration is, the higher the possibility that the next operation on the critical section will be damaging.

Q2.1.2:
	The yield run so slowly because it is a system call that is really time costy. The additional time goes to the kernal where it takes care of the trap. It is not possible to get a valid per-operation time because every thread is calling system call eventually, which adds up to a huge time consumption.

Q2.1.3:
	The time drops because the cost of system call is diluted by the increasing time cost of the "real" operations. When the curve of cost per operation meets a plateau where with increasing iteration, the time per operation decreases unnoticeable. 

Q2.1.4:
	They all looks the same because when the thread number is low, the competition between threads is unlikely. Therefore, they will, unlikely, wait to get the lock. As the number of thread increases, they will spend more time waiting to get the lock.

Q2.2.1:
	 For mutex-protected operations in Part-1 and Part-2, the correct times per operation appear to be much lower for the linked list operations. This is because we are dividing by the cost of synchronization (which is once per list operation) by the number of elements in the list, which we should not be doing. After making this correction, we still see that mutex synchronization goes up more quickly for lists than for adds. This is because the linked list locks are held much longer than the corresponding add locks, thus increasing the probability of conflict.
For part1, the curves of both spin-lock and compare-and-swap increases with number of thread, especially the spin. However, the curve of mutex increases at the beginning but decreases eventually. For part2, the curve of spin-lock increases while the mutex one decreases and oscillates in the end. The spin-lock is the most wasting one because the threads will stay in a loop till get the lock and it just wastes the register. Compare-and-swap is similar but it is not stuck in the loop, it actually copies the value from counter. Mutex is the most efficient one since the threads that not having the lock will sleep till one release the lock. 

Q2.2.2:
	For the mutex, the same issues discussed above in #2.2.1 still apply. Moreover, for few number of threads, the costs of spin-locks are almost the same as that of mutexes. However, as the number of threads increases, the costs of the spin-locks grows greater than that of the mutexes. This is due to the fact that the more threads there are, the more likely the threads will be competing for the same lock. Since the spin lock causes the thread to just spin and waste CPU cycles while waiting to acquire the lock, the spin lock's costs is greater than that of the mutex, which puts the thread to sleep so the CPU can do useful work while the thread is waiting for the lock.
 
